{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDyaXHLMdunA"
   },
   "source": [
    "# **Deep Learning LAB 3**\n",
    "\n",
    "Improving on last weeks lab 2, we will extend our model to use convolutional and pooling layers to improve the accuracy of the model\n",
    "\n",
    "This lab is slightly adapted from an online tutorial by Adrian Rosebrock.\n",
    "\n",
    "Read the code in each of the steps carefully with the aim of fully understand what is going on (the instructor will help as needed),. Then run each step.\n",
    "\n",
    "Once, you have finished going through all the steps, try to improve the test accuracy of the CNN, for example, by:\n",
    "\n",
    "*   using different activation function in the hidden layers\n",
    "*   increase number of layers\n",
    "*   changing pooling parameters\n",
    "*   augmenting the data\n",
    "\n",
    "Were you able to improve the test accuracy of the network? By how much? Which enhancements worked the best? Show your result to the lab instructor.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50tI6On4hjMg"
   },
   "source": [
    "# Step 1:  \"Upload\" the images in Colaboratory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtU5pZ9B9Qm-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Three thousand images of cats, dogs, and pandas (1000 each)\n",
    "if not os.path.exists('./lab2'):\n",
    "  !wget https://www.ru.is/~yngvi/ML/lab2.tgz\n",
    "  !tar -xzf lab2.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5k22kd-aiEW3"
   },
   "source": [
    "# Step 2: Import necessary Python packages\n",
    "\n",
    "Apart from the necessary Keras packages, we will be using several other support libraries to make our life easier, for example, OpenCV for reading in (and manipulating) images, SciKit for transformations, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XC2BTSUMiUMb",
    "outputId": "7c7e50c5-80dd-4412-d8c9-77c3c06cbb9d"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, SpatialDropout1D\n",
    "from keras.optimizers import SGD, rmsprop, Adam, Nadam\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 42   # include for reproducability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFyXNJZ7fIMa"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LQ_8yjHiWlS"
   },
   "source": [
    "# Step 3: Read in the filesystem paths of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f06FmCceipQv",
    "outputId": "be477ac7-fcc9-4300-80c5-460c66a098ba"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "# Specify locations of input and output files.\n",
    "tutorial_dir = \"./lab2/\"\n",
    "args = {}\n",
    "args[\"dataset\"] = tutorial_dir + \"animals/\"\n",
    "args[\"model\"]   = tutorial_dir + \"output/simple_nn.model\"\n",
    "args[\"plot\"]    = tutorial_dir + \"output/simple_nn_plot.png\"\n",
    "\n",
    "# Read in the file paths of the images to use for the training.\n",
    "image_paths = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(args[\"dataset\"]):\n",
    "    for file in filenames:\n",
    "        if '.jpg' in file and not file.startswith('.'):\n",
    "              image_paths.append(os.path.join(dirpath, file))\n",
    "                \n",
    "random.seed(random_seed)\n",
    "random.shuffle(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IDNSGZRiD9xg"
   },
   "source": [
    "# Define the preprocesses dimensions of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8lOPNPYECnN"
   },
   "outputs": [],
   "source": [
    "sz = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_hHPzR6iqje"
   },
   "source": [
    "# Step 4: Read in and preprocess the images\n",
    "Define a function preprocess_img which given an image and a variable called size, returns a preprocessed image, which is more suitable for a convolutional neural network\n",
    "\n",
    "The actions that we want to do are as follows:\n",
    "\n",
    "\n",
    "1.   Resize the image to be of dimensions size x size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76A8z0Pm9QnX"
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img, size):\n",
    "  img2 = cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_NEAREST)\n",
    "  img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "  return img2\n",
    "\n",
    "def show_images(imgs, grid_size=3):\n",
    "  f, axarr = plt.subplots(grid_size,grid_size, figsize=(15, 15))\n",
    "  for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "      axarr[i,j].imshow(imgs[i*grid_size+j])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7MTyKglsCR5"
   },
   "source": [
    "# Step 5: Split the data into test and training set, and reformat target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zncY-8TdjIUw"
   },
   "outputs": [],
   "source": [
    "input_data   = []\n",
    "input_labels = []\n",
    "original_imgs = []\n",
    "for image_path in image_paths:\n",
    "    image = cv2.imread(image_path)\n",
    "    original_imgs.append(image)\n",
    "    image = preprocess_img(image, sz)\n",
    "    input_data.append(image)\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "    input_labels.append(label)\n",
    "    \n",
    "input_data   = np.array(input_data)# maybe this should be changed\n",
    "input_labels = np.array(input_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(trainX, testX, trainY, testY) = train_test_split(input_data, \n",
    "                                                  input_labels, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=random_seed)\n",
    "# Convert the target categorial labels into binary vectors \n",
    "# (for 2-class, binary classification you should use Keras' \n",
    "#  to_categorical function instead as the scikit-learn's LabelBinarizer)\n",
    "lb = LabelBinarizer()    # ... from scikit\n",
    "trainY = lb.fit_transform(trainY)  # ... from scikit\n",
    "testY  = lb.transform(testY)       # ... from scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kvzr1f9yDA24"
   },
   "source": [
    "# Original images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "Xt_3dBfoDGol",
    "outputId": "38ecde9c-d377-47fa-992d-ec1b8cb65a5a"
   },
   "outputs": [],
   "source": [
    "show_images(original_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lHkSlM3PDK_C"
   },
   "source": [
    "# Preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "colab_type": "code",
    "id": "JPG_q1k7DN91",
    "outputId": "a7d0ab6d-7798-4f0e-90ab-1946bf1c2952"
   },
   "outputs": [],
   "source": [
    "show_images(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rh9oORkrkdiZ"
   },
   "source": [
    "# Step 5: Create the ANN model, train it, and then evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3748
    },
    "colab_type": "code",
    "id": "50oeyBXLkhzk",
    "outputId": "4b452ecf-7642-4a9e-b63b-44f7341ee3d3"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "trainX = trainX.reshape(trainX.shape[0],sz,sz,3) # if you've converted everything to grayscale\n",
    "testX = testX.reshape(testX.shape[0],sz,sz,3)    # then change the last argument to 1 instead of 3\n",
    "\n",
    "chanDim = -1 # change this to 1 if you're using theano as a backend\n",
    "\n",
    "# Layer 1\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=trainX.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "# Layer 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "# Layer 4\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "# Layer 5\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 6\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "# Layer 7\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "# Layer 8\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "# Layer 9\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 10\n",
    "model.add(Flatten()) # it is important to flatten your 2d tensors to 1d when going to FC-layers\n",
    "model.add(Dense(512, bias_initializer='ones'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(len(lb.classes_)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "trainX = trainX.astype('float64')\n",
    "testX = testX.astype('float64')\n",
    "\n",
    "#trainX /= 255.0\n",
    "#testX /= 255.0\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# Now train the ANN ...\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=EPOCHS, batch_size=32)\n",
    "\n",
    "# ... and then evaluate it.\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\t       predictions.argmax(axis=1), target_names=lb.classes_))\n",
    "\n",
    "# Store the model on disk.\n",
    "print(\"[INFO] serializing and storing the model ...\")\n",
    "model.save(args[\"model\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IMahKBI4kA8L"
   },
   "source": [
    "# Visualization of the CNN\n",
    "\n",
    "It is important to note that the sizes of each layer have been reduced to make the image more understandable, the image is more to emphasize the actions done in each layer.\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/Sigurdurhelga/Sigurdurhelga.github.io/master/Downloads/cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBfa3Rno0sHc"
   },
   "source": [
    "# Output a graph with information about learning progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "RSk_Sp570ynl",
    "outputId": "557353e2-4877-488b-91ad-c335e19e935e"
   },
   "outputs": [],
   "source": [
    "# Plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "#plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "#plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02S471CNsNpc"
   },
   "source": [
    "# Possible Improvements\n",
    "\n",
    "Now you should try to play around with the data to get the highest possble evaluation score you can get. There are many possible steps for you to take, we recommend these\n",
    "\n",
    "*   Bolster your dataset through data augmentation, to do so just add additional steps in the preprocess_img function\n",
    "*   Play with the Neural Network with additional layers, other optimizers, adding regularizers, or any other thing you might think of\n",
    "*   Do bagging/boosting or implement other models and setup an ensemble method\n",
    "\n",
    "\n",
    "With minimal adjustments you should reach accuracy in the 75% region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dy_TUuEhtFBG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep Learning Lab 3.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
